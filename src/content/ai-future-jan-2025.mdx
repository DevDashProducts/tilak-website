---
title: "AI: What can we do?"
publishedAt: "2025-01-18"
summary: "Exploring the fascinating possibilities of AI-human interaction through intuitive interfaces. This article delves into a future where AI can be accessed through drawing and natural gestures, potentially revolutionizing how we interact with technology. We examine the potential for AI agents to process visual inputs and transform them into meaningful interactions, and how this could fundamentally change our relationship with artificial intelligence."
image: "/blogs/image-2.png"
tags: "AI, Hypothesis, Future thinking"
---

# What will the future for AI look like? 

Nitesh Pant  
May 28, 2024

Imagine a world where AI can be accessed by drawing 

So, a person draws on a mobile tablet and talks with an AI agent (partially embedded in the tablet, partially in the cloud). Instead of typing everything as we do now, people can interact with AI using a pen, touch, and digital screen.

To do that, we'd need to design an AI agent for the initial processing where the AI agent takes the initial process and changes it into a prompt that the second AI agent can then use. Or maybe the graphic AI models will be 1000x better in 10 years from now?

In fact, this might change the trajectory of how the second AI agent uses the prompt or is interacted with. Remeber that human-type-like design interface is rudimentary and what is always good is pure code. So, an AI GUI could really let go of the coversion of text prompt to code, and just turn human gestures into code.

Either this will be true or I am just day dreaming. 